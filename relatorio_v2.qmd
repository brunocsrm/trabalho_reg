---
title: "Relatório"
format: pdf 
geometry:
  - left= .2in
editor: source
author: Tomás Bernardes & Bruno Ribeiro
---

# Objetivos

Este trabalho procura analisar o banco de dados *penguins*, por meio de regressões lineares realizadas usando os softwares python e R.

![penguins a serem estudados](https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/gorman-penguins.jpg){fig-align="center" width="212"}

```{r}
#| warning: false

library(palmerpenguins)
library(tidyverse)
library(reticulate)
library(gridExtra)
library(GGally)
library(reglin)
library(sjPlot)
library(car)
library(reglin)
```

```{python}
#| warning: false
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import plotly.express as px
from scipy.stats import shapiro, anderson, kstest
```

```{r}
dados <- penguins
dados = drop_na(dados)
head(penguins)
```

```{python}
#| output: false
#| warning: false
# Verificando valores nulos
dados_py = r.dados
dados_py.isnull().sum()
```

# Analise grafica

Iremos, antes de tudo, realizar uma análise exploratória dos dados para que, desta forma, possamos criar nossas primeiras hipótese. Para tal, utilizaremos o pacote **ggplot**

```{r}
#| warning: false
body_mass_plot <- ggplot(data = penguins) + #- distribution of the response variable
  aes(x = body_mass_g) +
  geom_histogram(color = "red", binwidth = 0.5) +
  xlab("Penguin body mass (g)")

species_plot <- ggplot(data = penguins) + #- distribution of the explanatory variable
  aes(x = species) +
  geom_bar(fill = "orange", binwidth = 0.5) +
  xlab("Penguin species") +
  geom_text(aes(label = ..count..), 
            stat = "count", 
            vjust = 1.5, 
            colour = "black")

bill_length_plot <- ggplot(data = penguins) + #- distribution of the explanatory variable
  aes(x = bill_length_mm) +
  geom_histogram(fill = "yellow", colour = "white", binwidth = 0.5) +
  xlab("Penguin bill length (mm)")

bill_depth_plot <- ggplot(data = penguins) + #- distribution of the explanatory variable
  aes(x = bill_depth_mm) +
  geom_histogram(fill = "green", colour = "white", binwidth = 0.5) +
  xlab("Penguin bill depth (mm)")

flipper_length_plot <- ggplot(data = penguins) + #- distribution of the explanatory variable
  aes(x = flipper_length_mm) +
  geom_histogram(fill = "blue", colour = "blue", binwidth = 0.5) +
  xlab("Penguin flipper length (mm)")

penguin_sex_plot <- ggplot(data = penguins) + #- distribution of the explanatory variable
  aes(x = sex) +
  geom_bar(fill = "purple", binwidth = 0.5) +
  xlab("Penguin sex (M of F)") +
  geom_text(aes(label = ..count..), 
            stat = "count", 
            vjust = 1.5, 
            colour = "black")
```

```{r}
#| warning: false
grid.arrange(body_mass_plot, species_plot, bill_length_plot, bill_depth_plot, flipper_length_plot, penguin_sex_plot)
```

```{r}
b1 <- ggplot(dados, aes(x = species, y = body_mass_g, fill = species)) + 
  stat_boxplot(geom = "errorbar",
               width = 0.15) + 
  geom_boxplot() +
  xlab("Espécies") + 
  ylab("Massa Corporal (g)") +
  theme_light()


b2 <- ggplot(dados, aes(x = island, y = body_mass_g, fill = island)) + 
  stat_boxplot(geom = "errorbar",
               width = 0.15) + 
  geom_boxplot() +
  xlab("Ilhas") + 
  ylab("Massa Corporal (g)") +
  theme_light()

b3 <- ggplot(dados, aes(x = sex, y = body_mass_g, fill = sex)) + 
  stat_boxplot(geom = "errorbar",
               width = 0.15) + 
  geom_boxplot() +
  xlab("sexo") + 
  ylab("Massa Corporal (g)") +
  theme_light()

p1 <- ggplot(dados, aes(x = body_mass_g, fill = species)) + 
  geom_histogram( color="#e9ecef", position = 'identity') + 
  xlab("Massa Corporal (g)") +
  ylab("Frequência") + 
  theme_light()


p2 <- ggplot(dados, aes(x = body_mass_g, fill = island)) + 
  geom_histogram( color="#e9ecef", position = 'identity') + 
  xlab("Massa Corporal (g)") +
  ylab("Frequência") + 
  theme_light()


p3 <- ggplot(dados, aes(x = body_mass_g, fill = sex)) + 
  geom_histogram( color="#e9ecef", position = 'identity') + 
  xlab("Massa Corporal (g)") +
  ylab("Frequência") + 
  theme_light()

grid.arrange(p1, b1, p2, b2, p3, b3)
```

```{r}
#| warning: false
ggpairs(data = penguins,
        columns = c("species", "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "sex", "body_mass_g"))
```

No gráfico acima a diagonal principal fornece-nos a distribuição aproximada da variável. Acima da diagonal, temos as medidadas de correlação e abaixo dela, é mostrado o scatterplot entre duas variáveis com o intuito de observar se há correlação.

Do gráfico, é possível perceber uma forte correlação entre *body_mass* e todas as outras variaveis quantitativas, isto é, *bill_length*,*bill_depth*,**flipper_length**, o que pode causar um problema de multicolinearidade no nosso modelo.

# Hipoteses a serem testadas

Dado a primeira analise feita por meio dos graficos, iremos construir modelos analisando a variavel resposta em relação as variaveis quantitativas individualmente e simultaneamente. Esperamos que todos os parametros sejam significativos, uma vez que, quanto mais largas são as caracteristicas morfologicas do penguin, maior sera o seu peso, assim como indicado pela correlação dos gráficos anteriores.

# Analise exploratoria de alguns modelos

Primeiro, queremos verificar a a relação entre body_mass_g e bill_length_mm, bill_depth_mm e flipper_length_mm individualmente. Lembrando que estaremos testando as hipóteses

```{python}
#| output: false
dados_py = dados_py.dropna()
```

```{python}
#| output: false
dados_py.isnull().sum()
```

### *body_mass_g* vs *bill_length_mm*

```{python}
model_1 = smf.ols(formula = 'body_mass_g ~ bill_length_mm', data = dados_py)
```

```{r}
ggplot(
  dados,
  aes(x = bill_length_mm, y = body_mass_g)) +
  geom_point(aes(color = species,
                 shape = island,
                 size = sex)) +
  geom_smooth(method = "lm", se = T, color = 'darkred') +
  theme_minimal()
```

### *body_mass_g* vs *bill_depth_mm*

```{python}
model_2 = smf.ols(formula = 'body_mass_g ~ bill_depth_mm', data = dados_py)
print(model_2.fit().summary())
```

```{r}
ggplot(
  dados,
  aes(x = bill_depth_mm, y = body_mass_g)) +
  geom_point(aes(color = species,
                 shape = island,
                 size = sex)) +
  geom_smooth(method = "lm", se = T, color = 'darkred') +
  theme_minimal()
```

### *body_mass_g* vs *flipper_depth_mm*

```{python}
model_3 = smf.ols(formula = 'body_mass_g ~ flipper_length_mm', data = dados_py)
print(model_3.fit().summary())
```

```{r}
ggplot(
  dados,
  aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(aes(color = species,
                 shape = island,
                 size = sex)) +
  geom_smooth(method = "lm", se = T, color = 'darkred') +
  theme_minimal()
```

Note que em todos os valores as variáveis são significativas, uma vez que em todos pvalor = 0 \< 0.05 e, portanto, rejeitamos a hipótese nula. Pelos graficos percebemos três aspectos importantes:

\- As especies dos penguins estão fortemente atreladas a uma unica ilha, o que pode acarretar em um problema de multicolinearidade.

\- Naturalmente, os penguins machos são mais pesados do que as femeas.

\- Em alguns casos,as especies formam clusters bastante distintos, o que sugere que a o uso de uma variavel indicadora da especies seja necessaria.

Todas estas descobertas nos ajudarão a melhorar ainda mais o nosso modelo.

Agora, vamos tentar adicionar múltiplas variáveis independentes à fórmula

```{python}
model_4 = smf.ols(formula = 'body_mass_g ~ bill_length_mm + bill_depth_mm', data = dados_py)
print(model_4.fit().summary())
```

```{python}
model_5 = smf.ols(formula = 'body_mass_g ~ bill_length_mm + flipper_length_mm', data = dados_py)
print(model_5.fit().summary()) 
```

Note que *bill_length_mm* deu não significativo no model_5

```{python}
model_6 = smf.ols(formula = 'body_mass_g ~ bill_depth_mm + flipper_length_mm', data = dados_py)
print(model_6.fit().summary()) 
```

No modelo 6, *bill_depth_mm* deu não significativo. Agora, vamos fazer um modelo com as 3 variáveis juntas uma vez que já analisamos individualmente, dois a dois, agora faremos três a três.

```{python}
model_7 = smf.ols(formula = 'body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm', data = dados_py)
print(model_7.fit().summary()) 
```

O que concluímos é que, enquanto bill_depth e bill_length são estatísticamente significativos quando usados juntos, ao serem combinados com flipper_length, eles se tornam insignificantes.

Observamos também que, pelo grafico, o tipo de especie e o sexo aparentam ter algum tipo relevancia para a regressão,o que esta de acordo com nossas suposições inciais.

```{python}
models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7]
model_summaries = pd.DataFrame({
  'Model': [f'Model {i}' for i in range(1, 8)],
  'R-squared': [model.fit().rsquared for model in models],
  'AIC': [model.fit().aic for model in models]
  
})
model_summaries
```

É possível concluir que model_3 é melhor (o que só possui o intercepto e flipper) pois nos casos em que temos flipper e bill, a segunda sempre da não significativa e caímos no modelo apenas com flipper e intercepto.

# Adicionando Variaveis Indicadoras

Como visto pelos gráficos e analises anteriores, observamos que o uso de variaveis indicadoras aparenta ser relevante para o nosso modelo.Vamos levar em conta agora as suposições descobertas e criaremos um modelo que leva em conta dois interceptos extras, o da especie e o do sexo.

```{python}
model_8 = smf.ols(formula='body_mass_g ~ bill_length_mm + bill_depth_mm +'
                           ' flipper_length_mm + species + sex',
                  data=dados_py)
print(model_8.fit().summary())

```

Vemos que este modelo aparenta ser muito melhor, pois todas as variaveis demonstram ser significativas. Compararemos agora este novo modelo com o anterior.

```{python}
models = [model_7, model_8]
model_summaries = pd.DataFrame({
  'Model': [f'Model {i}' for i in range(7, 9)],
  'R-squared': [model.fit().rsquared for model in models],
  'AIC': [model.fit().aic for model in models]
  
})
model_summaries
```

Concluimos, portanto, que o o ultimo modelo demonstra ser melhor que todos os outros, ja que seu R2 é maior e o seu AIC é muito menor, ou seja, ele explica uma porcentagem maior da variavel resposta do que os outros modelos.

Num primeiro momento, parece razoável considerar a inclusão de variaveis com interação para este modelo. No entanto, os resultados abaixo evidenciam que essa suposição se mostra pouco apropriada para o nosso estudo.

```{python}
model_9 = smf.ols(formula='body_mass_g ~ bill_length_mm + bill_depth_mm + '
                          'flipper_length_mm + species + sex + '
                          'species:bill_length_mm + species:bill_depth_mm + '
                          'species:flipper_length_mm',
                  data=dados_py)
print(model_9.fit().summary())

```

Vemos que este modelo não aparenta ser muito bom, pois tem muitas variaveis e poucas delas relevantes para o modelo

Isso se deve, possivelmente, porque o ganho de peso nas diferentes espécies de pinguins segue um padrão similar em relação ao aumento das características morfológicas que estamos analisando.

Em contraste com os resultados anteriores, vemos que a interação com a varivel sexo, de fato, proporciona um modelo ligeiramente supeior.

```{python}
model_10 = smf.ols(formula='body_mass_g ~ bill_length_mm + bill_depth_mm + ' +
                           'flipper_length_mm + species + sex +' +
                           'sex:bill_length_mm + sex:bill_depth_mm + ' +
                           'sex:flipper_length_mm',
                   data=dados_py)
print(model_10.fit().summary())

```

```{python}
models = [model_8, model_9,model_10]
model_summaries = pd.DataFrame({
  'Model': [f'Model {i}' for i in range(8, 11)],
  'R-squared': [model.fit().rsquared for model in models],
  'AIC': [model.fit().aic for model in models]
  
})
model_summaries
```

Podemos testar se as variaveis adicionadas podem, de fato ser consideradas importantes ou não com o teste de soma de quadrados extras isto é, estaremos testando estas hipoteses: \[codigo do latex aqui\]

```{python}

def soma_extra(model_1, model_2):
    sse_1 = sum(model_1.resid ** 2)
    sse_2 = sum(model_2.resid ** 2)
    
    df_1 = model_1.df_resid
    df_2 = model_2.df_resid

    gl = df_1 - df_2

    sse_extra = sse_1 - sse_2
    f_statistic = (sse_extra / gl) / (sse_2 / df_2)
    saida = {
        "SQExtra": sse_extra,
        "df1":df_1,
        "df2":df_2,
        "gl": gl,
        "F0": f_statistic,
    }
    return saida

resultado = soma_extra(model_8.fit(), model_10.fit())
print(resultado)
```

```{r}
F0 = 7.343
gl = 2
df2 = 326
pf(F0,gl,df2,lower.tail = F)
```

Ou seja, rejeitamos a hipotese nula, o que demonstra que pelo menos um dos novos betas são significativos, isto é facilemente analisado pelos p valores dos testes t's feitos acima. Contudo, apesar de termos resultados satisfatorios nestes testes, observamos que o fator de inflação da variancia do modelo 10 é bastante alto para as novas variaveis:

```{r}
fit_10 = lm(body_mass_g ~ bill_length_mm + 
              bill_depth_mm + 
              flipper_length_mm + 
              species + 
              sex +
              sex:bill_length_mm + 
              sex:bill_depth_mm  + 
              sex:flipper_length_mm,
            data = dados)
vif(fit_10)
```

Ou seja, apesar da breve porem existente superioridade do modelo 10, o modelo 8 ainda demonstra ser preferivel, ja que consegue explicar os dados de forma bastante similar mas operando com muito menos variaveis e sem o problema da multicolinearidade, ja que o seu VIF é muito baixo.

```{r}
fit_8 = lm(body_mass_g ~ bill_length_mm + 
              bill_depth_mm + 
              flipper_length_mm + 
              species,
            data = dados)
vif(fit_8)
```

E, para concluir, o uso das outras variaveis indicadores (ano e ilha) também pouco adicionam ao modelo total.

```{python}
model_11 = smf.ols(formula='body_mass_g ~ bill_length_mm + bill_depth_mm + ' +
                           'flipper_length_mm + species + island + year',
                   data=dados_py)
print(model_11.fit().summary())

```

Isto é bem perceptivel pelos gráficos, ja que a as ilhas e as especies aparentam estar bastante atreladas e as amostras ao longo dos anos também paracem ser bastante similares umas as outras.

```{r}
#| warning: false
dados2 = dados
dados2$year = as.factor(dados2$year )
ggplot(
  dados2,
  aes(x = bill_length_mm, y = body_mass_g,color = year)) +
  geom_point(aes(shape=species)) +
  scale_color_brewer(palette="Dark2")
```

# Verificação de adequação do modelo

Iremos agora fazer a analise de residuos do modelo que escolhemos o modelo 8.

```{r}
fit_8 <- lm(body_mass_g ~ bill_length_mm + 
              bill_length_mm + 
              flipper_length_mm + 
              species + 
              sex, data = dados)
ggresiduals(fit_8)
```

Conforme podemos observar no gráfico acima, o modelo 8 satisfaz a suposição de hocedasticidade bem como a de normalidade. Além disso, não há nenhum problema de escala entre as covariáveis e, não há valores outliers, apenas alguns pontos de alavanca e outros influentes.

```{python}
model_8 = smf.ols(formula = 'body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex', data = dados_py)

residuals = model_8.fit().resid

shapiro_test_stat, shapiro_p_value = shapiro(residuals)
anderson_test_stat, anderson_critical_values, anderson_significance_levels = anderson(residuals)
ks_test_stat, ks_p_value = kstest(residuals, 'norm')


normality_test_results = pd.DataFrame({
    'Test': ['Shapiro-Wilk', 'Anderson-Darling', 'Kolmogorov-Smirnov'],
    'Test Statistic': [shapiro_test_stat, anderson_test_stat, ks_test_stat],
    'p-value': [shapiro_p_value, None, ks_p_value]
})


print(normality_test_results)
```

Todos os testes de normalidade, concluem que os resíduos são normais.
